[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 2300 Intro to Data Science",
    "section": "",
    "text": "Introduction\nThese are the lecture notes for STA 2300 - Intro to Data Science\nPrerequisites: None\n\nCourse Description:\nPrinciples of data science, including problem workflow, variable types, visualization, modeling, programming, data management and cleaning, reproducibility, and big data.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "01.html",
    "href": "01.html",
    "title": "1  Session 1 – R setup",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1 – R setup</span>"
    ]
  },
  {
    "objectID": "01.html#objectives",
    "href": "01.html#objectives",
    "title": "1  Session 1 – R setup",
    "section": "",
    "text": "Explore the data‑science lifecycle. The R for Data Science introduction models data science as a cycle: you begin by importing and tidying raw data; then understand it through an iterative loop of transforming, visualising and modelling; and finally communicate your results. Programming surrounds all of these steps and supports them. Today you will learn why each component is important and how they connect.\nRecognise the tools you need. To run the code in R for Data Science you need R, RStudio, the tidyverse package collection and a handful of other packages. We will install R (from the Comprehensive R Archive Network), download RStudio (an integrated development environment), and install the tidyverse.\nPrepare your computing environment. By the end of class you should have R and RStudio installed, know how to install and load packages, and be able to run simple R commands (arithmetic, vector creation, summary statistics). We will also introduce a dataset that you will revisit throughout the semester.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1 – R setup</span>"
    ]
  },
  {
    "objectID": "01.html#notes",
    "href": "01.html#notes",
    "title": "1  Session 1 – R setup",
    "section": "Notes",
    "text": "Notes\n\nThe data‑science workflow\nData science is not a linear process. You first import data from files, databases or the web; tidy it so that each variable is a column and each observation a row; transform, visualise and model your data in an iterative loop to understand patterns and relationships; and then communicate your findings to others. Programming is a cross‑cutting skill that supports each of these phases. Throughout this course, you will move back and forth between these steps rather than following them in a strict order.\n\n\nTools and setup\nYou need four things to run the book’s code: R, RStudio, the tidyverse and some additional packages.\n\nR is the programming language you will use. Download the latest version from CRAN at https://cloud.r-project.org. A new major version of R is released once a year, with minor versions in between; updating regularly ensures compatibility.\n\nRStudio is an integrated development environment (IDE) for R. Download it from https://posit.co/download/rstudio-desktop/. RStudio is updated a couple of times a year. When you start RStudio, you will see a console pane for typing R code and an output pane for plots.\nThe tidyverse is a collection of packages for data manipulation, visualization and programming. To install all core tidyverse packages at once, run install.packages(\"tidyverse\") in the R console. After installation, load the tidyverse with library(tidyverse); this attaches packages such as dplyr, ggplot2, tidyr, readr, stringr, forcats, lubridate, purrr and tibble. You only need to install a package once, but you must load it in each new R session.\nOther packages. We will occasionally use packages outside the tidyverse (e.g., palmerpenguins, nycflights13, arrow, rvest, duckdb). When you encounter an error that a package is not installed, run install.packages(\"package_name\") to install the package.\n\n\n\nInstalling and testing your environment\n\nInstall R and RStudio as described above. Accept the default installation options.\n\nInstall the tidyverse. Open RStudio and run the following in the console:\n\n\ninstall.packages(\"tidyverse\")   # installs core tidyverse packages\nlibrary(tidyverse)               \n\n\nTry basic R commands. Use R as a calculator and practise creating vectors and computing summaries:\n\n\n2 + 2                  # arithmetic\n\n[1] 4\n\nx &lt;- c(1, 2, 3, 5, 7)  # create a numeric vector\nx * 2                  # vectorised multiplication\n\n[1]  2  4  6 10 14\n\nmean(x)                # compute the average\n\n[1] 3.6\n\nsum(x &gt; 4)             # count values greater than 4 (logical vector)\n\n[1] 2\n\n\nNotice that R performs operations element‑wise on vectors, and the assignment operator &lt;- stores values. Use descriptive variable names and indent your code neatly; we will discuss code style in a later class.\n\n\nTake‑aways\n\nThe data‑science process is iterative, looping through import, tidy, transform, visualize, model and communicate. Understanding develops as you cycle through these steps.\nTo do data science in R you need the R language, the RStudio IDE, the tidyverse package collection and other supporting packages. Installing and loading packages early will save time later.\nR is vectorized: arithmetic operations and functions operate on entire vectors. Use the assignment operator &lt;- to store results and choose descriptive variable names to write readable code.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1 – R setup</span>"
    ]
  },
  {
    "objectID": "02.html",
    "href": "02.html",
    "title": "2  Session 2 – Data visualization basics",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Session 2 – Data visualization basics</span>"
    ]
  },
  {
    "objectID": "02.html#objectives",
    "href": "02.html#objectives",
    "title": "2  Session 2 – Data visualization basics",
    "section": "",
    "text": "Appreciate the importance of visualization. A simple graph can convey more information than any other device. You will learn how the grammar of graphics underlies ggplot2.\nCreate basic plots. Use ggplot2 to draw scatterplots, bar charts and histograms.\nUnderstand variable types. Recognize when to use different plot types based on whether variables are categorical or numeric.\nPrepare for layering. Today’s material sets the stage for Session 3 on layering, where you’ll add geoms, adjust positions and facet plots.\n\n\nNotes\nWhy use ggplot2? R has several systems for making graphs, but ggplot2 is one of the most elegant and versatile. It implements the grammar of graphics—a coherent system for describing and building graphs. Learning this grammar enables you to create a wide range of plots with consistent syntax.\nBuilding your first plots The data-visualization chapter starts with a simple scatterplot to illustrate aesthetic mappings and geometric objects. Aesthetic mappings tie variables to graphical properties (x and y positions, colour, shape), while geoms specify the type of plot.\n\nScatterplots show the relationship between two numeric variables. For example, plotting penguin flipper length vs. body mass can reveal whether larger penguins tend to have longer flippers. Map species or island to colour or shape to uncover additional structure.\nBar charts display the distribution of a categorical variable—for example, counting penguins by species.\nHistograms reveal the distribution of a numeric variable. Choose a bin width that balances detail with clarity.\n\nTo illustrate these concepts, load the tidyverse and palmerpenguins packages, then experiment with commands like:\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\n\n\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\n\n\n\n\nBe sure to label axes and titles with labs(), choose appropriate scales, and consider transparency (alpha) to reduce overplotting.\n\n\nKey take‑awayss\n\nggplot2 implements a coherent grammar of graphics.\nScatterplots reveal relationships between numeric variables; bar charts and histograms show distributions.\nUnderstanding your variables (categorical vs. numeric) guides your choice of plot type.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Session 2 – Data visualization basics</span>"
    ]
  },
  {
    "objectID": "03.html",
    "href": "03.html",
    "title": "3  Session 3 – The layered grammar of graphics",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3 – The layered grammar of graphics</span>"
    ]
  },
  {
    "objectID": "03.html#objectives",
    "href": "03.html#objectives",
    "title": "3  Session 3 – The layered grammar of graphics",
    "section": "",
    "text": "Deepen your understanding of ggplot2. Explore the layered grammar of graphics—how aesthetic mappings, geometric objects and facets combine to build complex plots.\nMaster aesthetic mappings. Map variables to color, shape, size and alpha correctly. Avoid mapping categorical variables to size or alpha (it implies a false ordering) and note that mapping a categorical variable to shape uses only six shapes, so additional groups are dropped.\nLayer multiple geoms. Add multiple geoms to a plot (e.g., points and smooth lines) and distinguish between global and local aesthetic mappings. Use the group aesthetic to draw separate curves for each category.\nUse faceting and coordinate systems. Split data into panels using facet_wrap() or facet_grid() and adjust scales. Experiment with coordinate transforms such as coord_flip() and coord_polar().",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3 – The layered grammar of graphics</span>"
    ]
  },
  {
    "objectID": "03.html#notes",
    "href": "03.html#notes",
    "title": "3  Session 3 – The layered grammar of graphics",
    "section": "Notes",
    "text": "Notes\nLayered grammar of graphics – Every plot can be built from layers consisting of data, aesthetic mappings, geoms, optional statistical transformations, position adjustments and a coordinate system. Building plots layer by layer allows incremental refinement.\nAesthetic mappings – The aes() function connects variables to graphical attributes. Mapping a categorical variable to color is generally safe; mapping it to shape works but only six shapes are available; mapping to size or alpha is discouraged and yields warnings.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n# Mapping species to color and shape (safe if ≤ 6 categories)\nggplot(penguins, aes(x = flipper_length_mm,\n                     y = body_mass_g,\n                     color = species,\n                     shape = species)) +\n  geom_point()\n\n\n\n\n\n\n\n# Mapping a categorical variable to size or alpha generates warnings\nggplot(penguins, aes(x = flipper_length_mm,\n                     y = body_mass_g,\n                     size = species)) +\n  geom_point()  # Warning: Using size for a discrete variable is not advised\n\n\n\n\n\n\n\n\nMappings defined in ggplot() apply globally, while mappings inside a geom override them for that layer.\n\n# Global mapping applies color to both geoms\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE)\n\n\n\n\n\n\n\n# Local mapping overrides global color for the point layer only\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(method = \"loess\", se = FALSE)\n\n\n\n\n\n\n\n\nLayering geoms – Different geoms (e.g., geom_point, geom_smooth, geom_bar) draw different types of objects. Overlaying geoms reveals multiple aspects of the data. When using geoms like geom_smooth(), ggplot2 automatically groups data by discrete variables; you can explicitly set group to control grouping.\n\n# Overlay scatterplot with separate curves per species\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(aes(group = species), method = \"loess\", se = FALSE)\n\n\n\n\n\n\n\n\nFacets – Use facet_wrap() to create a grid of subplots for one categorical variable, and facet_grid() for two variables. You can allow axes to vary across facets with the scales argument.\n\n# Facet by island\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~ island)\n\n\n\n\n\n\n\n# Facet by species and sex with free y‑axis\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point() +\n  facet_grid(species ~ sex, scales = \"free_y\")\n\n\n\n\n\n\n\n\nCoordinate systems – Transform plots using different coordinate systems to improve interpretability. For example, swap axes using coord_flip() or create a polar bar chart with coord_polar().\n\n# Flip axes in a boxplot\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\n# Polar coordinates for a bar chart\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  coord_polar()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3 – The layered grammar of graphics</span>"
    ]
  },
  {
    "objectID": "04.html",
    "href": "04.html",
    "title": "4  Session 4 – Data transformation (I): filtering, arranging, selecting and mutating",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Session 4 – Data transformation (I): filtering, arranging, selecting and mutating</span>"
    ]
  },
  {
    "objectID": "04.html#objectives",
    "href": "04.html#objectives",
    "title": "4  Session 4 – Data transformation (I): filtering, arranging, selecting and mutating",
    "section": "",
    "text": "Understand the purpose of data transformation. You rarely get data in exactly the form needed for analysis. Transformation involves creating new variables, reordering or selecting observations, and renaming columns.\nUse dplyr verbs to manipulate rows and columns. Learn filter() to subset rows, arrange() to reorder rows, select() and rename() to choose or rename variables, and mutate() to create new columns.\nChain operations with the pipe. Use the pipe (|&gt; in base R or %&gt;% from magrittr) to express sequences of transformations in a readable way.\n\n\nNotes\nKey dplyr verbs – This session covers four of the five core verbs of dplyr:\n\nPick observations by their values: filter() subsets rows based on logical conditions.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n# Filter penguins to only Adelie species on Dream island\nadelie_dream = penguins |&gt; \n  filter(species == \"Adelie\", island == \"Dream\")\n\nadelie_dream |&gt; head()\n\n# A tibble: 6 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Dream            39.5          16.7               178        3250\n2 Adelie  Dream            37.2          18.1               178        3900\n3 Adelie  Dream            39.5          17.8               188        3300\n4 Adelie  Dream            40.9          18.9               184        3900\n5 Adelie  Dream            36.4          17                 195        3325\n6 Adelie  Dream            39.2          21.1               196        4150\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nfilter() takes the data frame as its first argument and any number of logical expressions as additional arguments. It returns a new data frame and does not modify the original.\nReorder the rows: arrange() sorts rows by one or more variables. Use desc() for descending order and remember that missing values are sorted to the end.\n\n# Arrange penguins by body mass (descending) and flipper length (ascending)\npenguins_sorted = penguins |&gt; \n  arrange(desc(body_mass_g), flipper_length_mm)\n\npenguins_sorted |&gt; head()\n\n# A tibble: 6 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo  Biscoe           49.2          15.2               221        6300\n2 Gentoo  Biscoe           59.6          17                 230        6050\n3 Gentoo  Biscoe           51.1          16.3               220        6000\n4 Gentoo  Biscoe           48.8          16.2               222        6000\n5 Gentoo  Biscoe           45.2          16.4               223        5950\n6 Gentoo  Biscoe           49.8          15.9               229        5950\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nPick variables by their names: select() quickly narrows a data frame to relevant columns. It supports helper functions like starts_with(), ends_with(), and contains().\n\n# Select species, island and body_mass_g columns\npenguins_subset = penguins |&gt; \n  select(species, island, body_mass_g)\n\npenguins_subset |&gt; head()\n\n# A tibble: 6 × 3\n  species island    body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;           &lt;int&gt;\n1 Adelie  Torgersen        3750\n2 Adelie  Torgersen        3800\n3 Adelie  Torgersen        3250\n4 Adelie  Torgersen          NA\n5 Adelie  Torgersen        3450\n6 Adelie  Torgersen        3650\n\n# Select all columns except those from bill_length to bill_depth\npenguins_except = penguins |&gt; \n  select(-(bill_length_mm:bill_depth_mm))\n\npenguins_except |&gt; head()\n\n# A tibble: 6 × 6\n  species island    flipper_length_mm body_mass_g sex     year\n  &lt;fct&gt;   &lt;fct&gt;                 &lt;int&gt;       &lt;int&gt; &lt;fct&gt;  &lt;int&gt;\n1 Adelie  Torgersen               181        3750 male    2007\n2 Adelie  Torgersen               186        3800 female  2007\n3 Adelie  Torgersen               195        3250 female  2007\n4 Adelie  Torgersen                NA          NA &lt;NA&gt;    2007\n5 Adelie  Torgersen               193        3450 female  2007\n6 Adelie  Torgersen               190        3650 male    2007\n\n\nTo rename a column without dropping others, use rename().\n\n# Rename flipper_length_mm to flipper_mm\npenguins = penguins |&gt; \n  rename(flipper_mm = flipper_length_mm)\n\npenguins |&gt; head()\n\n# A tibble: 6 × 8\n  species island bill_length_mm bill_depth_mm flipper_mm body_mass_g sex    year\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;      &lt;int&gt;       &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n1 Adelie  Torge…           39.1          18.7        181        3750 male   2007\n2 Adelie  Torge…           39.5          17.4        186        3800 fema…  2007\n3 Adelie  Torge…           40.3          18          195        3250 fema…  2007\n4 Adelie  Torge…           NA            NA           NA          NA &lt;NA&gt;   2007\n5 Adelie  Torge…           36.7          19.3        193        3450 fema…  2007\n6 Adelie  Torge…           39.3          20.6        190        3650 male   2007\n\n\nCreate new variables: mutate() adds new columns that are functions of existing columns. You can refer to variables created earlier in the same call.\n\n# Compute ratio of body mass to flipper length and total bill size\npenguins = penguins |&gt; \n  mutate(\n    mass_per_flipper = body_mass_g / flipper_mm,\n    bill_size = bill_length_mm + bill_depth_mm\n  )\n\npenguins |&gt; head()\n\n# A tibble: 6 × 10\n  species island bill_length_mm bill_depth_mm flipper_mm body_mass_g sex    year\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;      &lt;int&gt;       &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n1 Adelie  Torge…           39.1          18.7        181        3750 male   2007\n2 Adelie  Torge…           39.5          17.4        186        3800 fema…  2007\n3 Adelie  Torge…           40.3          18          195        3250 fema…  2007\n4 Adelie  Torge…           NA            NA           NA          NA &lt;NA&gt;   2007\n5 Adelie  Torge…           36.7          19.3        193        3450 fema…  2007\n6 Adelie  Torge…           39.3          20.6        190        3650 male   2007\n# ℹ 2 more variables: mass_per_flipper &lt;dbl&gt;, bill_size &lt;dbl&gt;\n\n\nIf you only want to keep the new variables, use transmute().\n\nCombining operations with the pipe – Stringing multiple operations together can be awkward when saving intermediate objects. The pipe (|&gt; or %&gt;%) passes the result of one call to the next, making code easier to read.\n\n# Calculate average body mass by species in a single pipeline\nspecies_summary = penguins |&gt;\n  group_by(species) |&gt;\n  summarise(\n    count = n(),\n    mean_mass = mean(body_mass_g, na.rm = TRUE)\n  ) |&gt;\n  arrange(desc(mean_mass))\n\nspecies_summary |&gt; head()\n\n# A tibble: 3 × 3\n  species   count mean_mass\n  &lt;fct&gt;     &lt;int&gt;     &lt;dbl&gt;\n1 Gentoo      124     5076.\n2 Chinstrap    68     3733.\n3 Adelie      152     3701.\n\n\nThe pipe should be read as “then”: group by species then summarise then arrange the result.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Session 4 – Data transformation (I): filtering, arranging, selecting and mutating</span>"
    ]
  },
  {
    "objectID": "05.html",
    "href": "05.html",
    "title": "5  Session 5 – Data transformation (II): grouping and summarizing",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 5 – Data transformation (II): grouping and summarizing</span>"
    ]
  },
  {
    "objectID": "05.html#objectives",
    "href": "05.html#objectives",
    "title": "5  Session 5 – Data transformation (II): grouping and summarizing",
    "section": "",
    "text": "Change the unit of analysis with grouping. Use group_by() to organize data into subsets (groups) so that subsequent operations operate within each group rather than on the whole data set.\nCompute summaries across groups. Apply summarize() to compute summary statistics (counts, means, medians, etc.) for each group. Understand that summarize() returns one row for each combination of grouping variables.\nUse helper functions. Learn to use helpers like n() and n_distinct() within summarize() to count observations and distinct values.\nSelect top or bottom observations per group. Use slice_max() and slice_min() to find the largest or smallest values within each group.\nEnhance pipelines. Continue to use the pipe (|&gt; or %&gt;%) to link group_by(), summarize() and other verbs into clear analytical workflows.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 5 – Data transformation (II): grouping and summarizing</span>"
    ]
  },
  {
    "objectID": "05.html#notes",
    "href": "05.html#notes",
    "title": "5  Session 5 – Data transformation (II): grouping and summarizing",
    "section": "Notes",
    "text": "Notes\nGrouping – group_by() does not change the data itself; it changes how dplyr verbs operate. After grouping, verbs like summarize(), mutate(), and filter() perform their operations separately on each group.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n# Group penguins by species and island\npenguins_by &lt;- penguins |&gt; group_by(species, island)\n\npenguins_by\n\n# A tibble: 344 × 8\n# Groups:   species, island [5]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSummarizing – summarize() collapses multiple rows to a single row for each group. Without any grouping, it returns a single row summarizing the entire data frame.\n\n# Summarize mean body mass and count per species-island group\npenguin_summary &lt;- penguins |&gt;\n  group_by(species, island) |&gt;\n  summarize(\n    count = n(),  # number of observations\n    mean_mass = mean(body_mass_g, na.rm = TRUE),\n    sd_mass = sd(body_mass_g, na.rm = TRUE),\n    distinct_years = n_distinct(year)\n  )\n  \n  penguin_summary\n\n# A tibble: 5 × 6\n# Groups:   species [3]\n  species   island    count mean_mass sd_mass distinct_years\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;          &lt;int&gt;\n1 Adelie    Biscoe       44     3710.    488.              3\n2 Adelie    Dream        56     3688.    455.              3\n3 Adelie    Torgersen    52     3706.    445.              3\n4 Chinstrap Dream        68     3733.    384.              3\n5 Gentoo    Biscoe      124     5076.    504.              3\n\n\nIn summarize(), the summary functions must return a single value. Functions such as mean(), median(), sd() and counts like n() and n_distinct() are typical.\nUngrouping – After summarizing, grouping remains; use ungroup() if you wish to remove grouping for subsequent operations. Alternatively, the .groups argument in summarize() can control the grouping structure of the result.\nFinding extremes within groups – slice_max() and slice_min() extract rows with the highest or lowest values within each group.\n\n# Top 3 diamonds by price for each cut\ntop_diamonds &lt;- diamonds |&gt;\n  group_by(cut) |&gt;\n  slice_max(order_by = price, n = 3, with_ties = FALSE)\n\ntop_diamonds\n\n# A tibble: 15 × 10\n# Groups:   cut [5]\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2.01 Fair      G     SI1      70.6    64 18574  7.43  6.64  4.69\n 2  2.02 Fair      H     VS2      64.5    57 18565  8     7.95  5.14\n 3  4.5  Fair      J     I1       65.8    58 18531 10.2  10.2   6.72\n 4  2.8  Good      G     SI2      63.8    58 18788  8.9   8.85  0   \n 5  2.07 Good      I     VS2      61.8    61 18707  8.12  8.16  5.03\n 6  2.67 Good      F     SI2      63.8    58 18686  8.69  8.64  5.54\n 7  2    Very Good G     SI1      63.5    56 18818  7.9   7.97  5.04\n 8  2    Very Good H     SI1      62.8    57 18803  7.95  8     5.01\n 9  2.03 Very Good H     SI1      63      60 18781  8     7.93  5.02\n10  2.29 Premium   I     VS2      60.8    60 18823  8.5   8.47  5.16\n11  2.29 Premium   I     SI1      61.8    59 18797  8.52  8.45  5.24\n12  2.04 Premium   H     SI1      58.1    60 18795  8.37  8.28  4.84\n13  1.51 Ideal     G     IF       61.7    55 18806  7.37  7.41  4.56\n14  2.07 Ideal     G     SI2      62.5    55 18804  8.2   8.13  5.11\n15  2.15 Ideal     G     SI2      62.6    54 18791  8.29  8.35  5.21\n\n\nPipelines – Continue chaining operations: group, summarize, arrange, and visualize, reading the pipe as “then”. Example:\n\n# Relationship between diamond carat and mean price by cut\ndiamond_summary &lt;- diamonds |&gt;\n  group_by(cut) |&gt;\n  summarise(\n    count = n(),\n    mean_carat = mean(carat),\n    mean_price = mean(price)\n  ) |&gt;\n  arrange(desc(mean_price))\n\ndiamond_summary |&gt; \n  ggplot(aes(x = cut, y = mean_price)) +\n  geom_col()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 5 – Data transformation (II): grouping and summarizing</span>"
    ]
  },
  {
    "objectID": "06.html",
    "href": "06.html",
    "title": "6  Session 6 – Data import: reading CSV & flat files",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 6 – Data import: reading CSV & flat files</span>"
    ]
  },
  {
    "objectID": "06.html#objectives",
    "href": "06.html#objectives",
    "title": "6  Session 6 – Data import: reading CSV & flat files",
    "section": "",
    "text": "Read your own data into R. Up to now we have worked with datasets that come bundled with packages. In practice you will often need to import data from your own files. This session introduces the readr functions for reading plain‑text rectangular data (CSV, TSV and other delimited formats). You will learn how to specify file paths and handle column names, types and missing values.\nControl column names, missing values and types. When you run read_csv() it prints the number of rows and columns read and a summary of the column specification. You will learn how to rename variables, skip header lines, define which strings should be treated as missing, and override the type guessing heuristic that readr uses.\nRead multiple files and combine them. Real projects often involve multiple data files (for example, one file per month). You can pass a vector of file paths to read_csv() and use the id argument to record the source of each observation. We will practice finding files with list.files(), reading them into a single tibble and combining them using bind_rows().",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 6 – Data import: reading CSV & flat files</span>"
    ]
  },
  {
    "objectID": "06.html#notes",
    "href": "06.html#notes",
    "title": "6  Session 6 – Data import: reading CSV & flat files",
    "section": "Notes",
    "text": "Notes\n\nWhy import data?\nWorking with data included in R packages is convenient when you are learning, but eventually you need to apply the tools to your own data. R for Data Science notes that this chapter focuses on reading plain‑text rectangular files and provides practical advice for handling column names, types and missing data. The goal is to help you get your data into a tidy tibble so that you can immediately start transforming and visualizing it.\n\n\nReading CSV files with readr\nThe readr package is part of the tidyverse and provides fast functions for reading delimited files. The most common function is read_csv(), which expects a path to a comma‑separated file. When you read a file, readr prints a message showing the number of rows and columns, the delimiter used and the column specification. This message includes the guessed type for each column and can be silenced with show_col_types = FALSE.\n\nlibrary(tidyverse)\n\n# Example: reading a simple CSV file from a URL\nstudents = read_csv(\"https://pos.it/r4ds-students-csv\")\nstudents\n\n# A tibble: 6 × 5\n  `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n         &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n2            2 Barclay Lynn     French fries       Lunch only          5    \n3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n6            6 Güvenç Attila    Ice cream          Lunch only          6    \n\n# Suppress the column spec message\nstudents_quiet = read_csv(\"https://pos.it/r4ds-students-csv\", show_col_types = FALSE)\n\nUse the file argument to read files stored locally. It is good practice to keep data in a dedicated data/ folder within your project and refer to it using relative paths. If your file has a header row containing the names of the columns (as most CSVs do), readr uses it automatically. If not, set col_names = FALSE and optionally provide a vector of names via col_names = c(\"...\", ...).\n\n\nHandling missing values and non‑syntactic names\nA CSV file does not encode missing values explicitly, so readr treats empty fields as NA. In practice, missing values are often recorded with sentinel strings such as \"N/A\" or \".\". You can tell read_csv() which strings should be considered missing using the na argument. For example, in the students.csv file the string \"N/A\" is used to mark missing foods. By specifying na = c(\"N/A\", \"\"), readr converts those strings to NA.\n\nstudents2 = read_csv(\n  \"https://pos.it/r4ds-students-csv\",\n  na = c(\"N/A\", \"\")\n)\nstudents2\n\n# A tibble: 6 × 5\n  `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n         &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n2            2 Barclay Lynn     French fries       Lunch only          5    \n3            3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n6            6 Güvenç Attila    Ice cream          Lunch only          6    \n\n\nSometimes column names contain spaces or other characters that make them non‑syntactic in R. In that case they are surrounded by backticks in the tibble, and you must use backticks to refer to them. A simple solution is to rename the columns after import using rename() or the janitor::clean_names() helper (the latter converts names to snake_case).\n\n\nHow readr guesses column types\nBecause a CSV file does not contain type information, readr guesses the type of each column. It samples up to 1,000 values from across the file and asks: does the column contain only logical values? Only numbers? Does it match ISO8601 date format? If none of those tests succeed, readr assumes the column is a string. This heuristic works well for clean datasets but can fail when there are unexpected values (e.g., a period . to represent a missing number).\nWhen type guessing fails you can provide your own column specification via the col_types argument. This argument is a named list or a cols() specification where each name matches a column and each value is a type function (e.g., col_double(), col_integer(), col_character(), col_date(), col_datetime()). For example, if a numeric ID is misread as a number but should be a character (because you never intend to sum it), specify col_types = list(student_id = col_character()). readr provides nine column types including\n\nlogicals\ndoubles\nintegers\ncharacters\nfactors\ndates\ndate‑time\npermissive numbers\nskipped columns\n\n\n# A small CSV with a custom missing value \".\"\nsimple_csv = \"x\\n10\\n.\\n20\\n30\"\n\n# Default guess treats the period as a string\ndf_default = read_csv(simple_csv)\ndf_default\n\n# A tibble: 4 × 1\n  x    \n  &lt;chr&gt;\n1 10   \n2 .    \n3 20   \n4 30   \n\n# Override the type to double and inspect problems\ndf_num = read_csv(simple_csv, col_types = list(x = col_double()))\nproblems(df_num)  # shows where parsing failed\n\n# A tibble: 1 × 5\n    row   col expected actual file                                              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                                             \n1     3     1 a double .      C:/Users/Joshua_Patrick/AppData/Local/Temp/Rtmpcz…\n\n# Tell readr to treat \".\" as NA so guessing succeeds\ndf_fixed = read_csv(simple_csv, na = \".\")\ndf_fixed\n\n# A tibble: 4 × 1\n      x\n  &lt;dbl&gt;\n1    10\n2    NA\n3    20\n4    30\n\n\nIf you have many columns with the same type, you can set a default type using cols(.default = col_character()). To read only a subset of columns, use cols_only() with the columns you want.\n\n\nReading multiple files and combining them\nIn many projects you receive data split across multiple files—perhaps one file per month or per site. Instead of reading each file separately and then binding the results, you can pass a vector of file paths to read_csv(). readr will read all of them and stack the rows together. The optional id argument adds a column that records the file each row came from.\n\n# Suppose you have three monthly sales files stored in data/01-sales.csv, 02-sales.csv, 03-sales.csv\nsales_files = c(\"data/01-sales.csv\", \"data/02-sales.csv\", \"data/03-sales.csv\")\n\n# Read and combine, adding a 'file' column to identify the source\nsales = read_csv(sales_files, id = \"file\")\n\nYou often don’t know the names of all the files ahead of time. Use list.files() to find files whose names match a pattern (e.g., \"sales\\\\.csv$\") and set full.names = TRUE so the full path is returned.\n\n# Find all CSV files ending with 'sales.csv' in the data directory\nsales_files = list.files(\"data\", pattern = \"sales\\\\.csv$\", full.names = TRUE)\nsales_files\nsales = read_csv(sales_files, id = \"file\")\n\nOnce you have imported multiple files you can combine them explicitly with dplyr::bind_rows() or bind_cols(), depending on whether you want to stack rows or columns. bind_rows() requires identical column names, so pay attention to names and types when reading.\n\n\nWriting data back to disk\nreadr also provides write_csv() and write_tsv() for saving tibbles to disk. Remember that when you write to CSV the column specification is lost—you must regenerate types when reading the file again. For intermediate results consider using write_rds() and read_rds(), which store R objects in a binary format preserving types.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 6 – Data import: reading CSV & flat files</span>"
    ]
  },
  {
    "objectID": "07.html",
    "href": "07.html",
    "title": "7  Session 7 – Tidy data & pivoting",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Session 7 – Tidy data & pivoting</span>"
    ]
  },
  {
    "objectID": "07.html#objectives",
    "href": "07.html#objectives",
    "title": "7  Session 7 – Tidy data & pivoting",
    "section": "",
    "text": "Define tidy data. Understand the three rules that make a dataset tidy: each variable must live in its own column, each observation must occupy its own row, and each value must appear in a single cell. Appreciate why a consistent data structure makes it easier to learn and use tidyverse tools.\nLengthen data with pivot_longer(). Use pivot_longer() from the tidyr package to reshape untidy datasets by gathering column names into a new variable and their values into another variable. Learn how to select columns to pivot, specify the names of the new variables and optionally drop missing values.\nHandle multiple variables in column names. Recognize when column headers encode multiple pieces of information (e.g., method, gender and age) and use the names_to/names_sep arguments of pivot_longer() to split them into separate variables.\nWiden data with pivot_wider(). Use pivot_wider() to spread rows into columns when each observation is represented across multiple rows. Learn how to choose the names_from, values_from and id_cols arguments so that each row uniquely identifies an observation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Session 7 – Tidy data & pivoting</span>"
    ]
  },
  {
    "objectID": "07.html#notes",
    "href": "07.html#notes",
    "title": "7  Session 7 – Tidy data & pivoting",
    "section": "Notes",
    "text": "Notes\n\nWhat is tidy data?\nTidy data is a standard way to organize your datasets so that they work naturally with the tidyverse. In tidy data:\n\nEach variable is a column, each column is a variable. A dataset like table1 from R for Data Science has one column for each variable and is easiest to work with.\nEach observation is a row. Each row of a tidy data frame corresponds to one observation of all variables.\nEach value is a cell. Every cell contains a single value for one variable in one observation.\n\nThe pay‑off for tidying data is twofold. First, adopting a single consistent structure makes it easier to learn a suite of tools because they all assume the same underlying format. Second, placing variables in columns allows R’s vectorised functions to operate naturally.\n\n\nLengthening data with pivot_longer()\nMost real datasets aren’t tidy because they are organised for data entry or reporting rather than analysis. The pivot_longer() function lengthens data by gathering a set of columns into key–value pairs. Its most important arguments are:\n\ncols: which columns to pivot. You can specify them explicitly (bp1:bp2) or using tidyselect helpers such as starts_with().\nnames_to: the name of the new variable created from column names. For example, converting week columns (wk1, wk2, …) into a variable called week.\nvalues_to: the name of the variable that will hold the values from the pivoted columns.\nvalues_drop_na: set to TRUE to drop rows where all the pivoted columns contain NA.\n\nHere is a simple example using the built‑in billboard dataset, which records weekly Billboard chart positions. Each row is a song and each wk? column gives its rank in that week. To tidy this dataset, we gather the week columns into a new week variable and the ranks into a rank variable:\n\nlibrary(tidyverse)\nbillboard_long &lt;- billboard |&gt;\n  pivot_longer(\n    cols = starts_with(\"wk\"),\n    names_to = \"week\",\n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |&gt;\n  mutate(week = parse_number(week))\nbillboard_long |&gt; head()\n\n# A tibble: 6 × 5\n  artist track                   date.entered  week  rank\n  &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1    87\n2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2    82\n3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3    72\n4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4    77\n5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5    87\n6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6    94\n\n\nThis call transforms the 317 × 79 billboard tibble into a 5307 × 5 tibble with one row per song–week combination.\nWhen column names contain multiple pieces of information, you can split them into several new variables by supplying a vector of names and a separator. For example, the who2 dataset records TB cases with column names like sp_m_014, which combine the method (sp), gender (m) and age range (014). The following call extracts those parts into separate variables:\n\nwho2_long &lt;- who2 |&gt;\n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"),\n    names_sep = \"_\",\n    values_to = \"count\"\n  )\nwho2_long |&gt; head()\n\n# A tibble: 6 × 6\n  country      year diagnosis gender age   count\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1 Afghanistan  1980 sp        m      014      NA\n2 Afghanistan  1980 sp        m      1524     NA\n3 Afghanistan  1980 sp        m      2534     NA\n4 Afghanistan  1980 sp        m      3544     NA\n5 Afghanistan  1980 sp        m      4554     NA\n6 Afghanistan  1980 sp        m      5564     NA\n\n\nThe names_sep argument splits each original column name at the underscore and assigns the pieces to the new variables (diagnosis, gender, age). The values_to argument stores the counts.\n\n\nWidening data with pivot_wider()\nSometimes a single observation is spread across multiple rows, and you need to widen the data by creating new columns. The function pivot_wider() increases the number of columns and decreases the number of rows. It is particularly useful when you have long data with a variable that identifies the type of measurement and another variable with the corresponding value.\nThe key arguments are:\n\nnames_from: the column whose unique values will become new column names.\nvalues_from: the column containing the values to fill those new columns.\nid_cols: optional columns that uniquely identify each row; if you omit this, pivot_wider() will attempt to infer them but may produce duplicate rows.\n\nAs an example, the cms_patient_experience dataset from the Centers for Medicare & Medicaid Services records multiple performance measures for each healthcare organization. Each organization appears on multiple rows, one per measure. To put each organization on its own row with separate columns for each measure code, use pivot_wider():\n\ncms_wide &lt;- cms_patient_experience |&gt;\n  pivot_wider(\n    id_cols = starts_with(\"org\"),\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\ncms_wide |&gt; head()\n\n# A tibble: 6 × 8\n  org_pac_id org_nm  CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5 CAHPS_GRP_8\n  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 0446157747 USC CA…          63          87          86          57          85\n2 0446162697 ASSOCI…          59          85          83          63          88\n3 0547164295 BEAVER…          49          NA          75          44          73\n4 0749333730 CAPE P…          67          84          85          65          82\n5 0840104360 ALLIAN…          66          87          87          64          87\n6 0840109864 REX HO…          73          87          84          67          91\n# ℹ 1 more variable: CAHPS_GRP_12 &lt;dbl&gt;\n\n\nBy specifying the identifier columns (org_pac_id and org_nm), pivot_wider() ensures that each organisation occupies a single row and creates a column for each measure code. If you omit id_cols, you may see duplicate rows because pivot_wider() cannot uniquely identify observations on its own.\n\n\nKey take‑aways\n\nTidy data has a consistent structure: variables in columns, observations in rows and values in cells. This organization simplifies analysis and leverages R’s vectorization.\npivot_longer() gathers columns into key–value pairs. Use cols to select columns to gather, names_to and values_to to name the new variables, and values_drop_na to remove structural missing values.\nSplit multiple pieces of information encoded in column names with names_to and names_sep.\npivot_wider() spreads values across new columns, reversing a pivot_longer() when observations are spread across rows. Use names_from, values_from and (optionally) id_cols to control the reshaping.\nPractice on real data. Tidy datasets are not always ready-made; most analyses require some tidying. Being proficient with pivoting functions allows you to structure your data before visualizing, transforming or modelling.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Session 7 – Tidy data & pivoting</span>"
    ]
  },
  {
    "objectID": "08.html",
    "href": "08.html",
    "title": "8  Session 8 – Variable types I: logical & numeric vectors",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Session 8 – Variable types I: logical & numeric vectors</span>"
    ]
  },
  {
    "objectID": "08.html#objectives",
    "href": "08.html#objectives",
    "title": "8  Session 8 – Variable types I: logical & numeric vectors",
    "section": "",
    "text": "Distinguish logical and numeric vectors. Logical vectors contain only TRUE, FALSE or NA, whereas numeric vectors contain integers or doubles. Learn to convert strings to numbers with parse_double() and parse_number().\nCreate and combine logical vectors. Use comparison operators (&lt;, &lt;=, &gt;, &gt;=, !=, ==) to generate logical vectors and combine them with &, |, ! and xor(). Avoid short‑circuiting operators (&&, ||) inside data‑masking verbs. Understand how missing values propagate through comparisons and Boolean operations.\nSummarize logical vectors. Collapse logical vectors with any() and all() or coerce them to numeric and use sum()/mean() to count or compute the proportion of TRUEs. Detect missing values with is.na().\nPerform numeric operations and transformations. Recognize that R recycles shorter vectors in arithmetic. Use pmin()/pmax() for element‑wise minima and maxima, %/% and %% for modular arithmetic, logarithms for rescaling, round(), floor() and ceiling() for rounding, and cut() to bin numeric data.\nCompute numeric summaries. Compare the mean and median—the mean is sensitive to extreme values while the median is robust. Use quantiles to summarize tails and spread measures such as the standard deviation and interquartile range.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Session 8 – Variable types I: logical & numeric vectors</span>"
    ]
  },
  {
    "objectID": "08.html#notes",
    "href": "08.html#notes",
    "title": "8  Session 8 – Variable types I: logical & numeric vectors",
    "section": "Notes",
    "text": "Notes\n\nLogical vectors and comparisons\nLogical vectors are created by comparing values. They can take on three values: TRUE, FALSE or NA. Comparison operators return a logical vector with the same length as the input. For example:\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\nflights |&gt;\n  mutate(late_dep = dep_delay &gt; 30,      # TRUE if departure delay &gt; 30 min\n         early_arr = arr_delay &lt; 0) |&gt;   # TRUE if arrival was early\n  select(year:day, dep_delay, arr_delay, late_dep, early_arr) |&gt;\n  head(5)\n\n# A tibble: 5 × 7\n   year month   day dep_delay arr_delay late_dep early_arr\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;    &lt;lgl&gt;    \n1  2013     1     1         2        11 FALSE    FALSE    \n2  2013     1     1         4        20 FALSE    FALSE    \n3  2013     1     1         2        33 FALSE    FALSE    \n4  2013     1     1        -1       -18 FALSE    TRUE     \n5  2013     1     1        -6       -25 FALSE    TRUE     \n\n\nBe cautious when comparing floating‑point numbers. Tiny rounding errors mean that equality tests may fail. To check approximate equality use dplyr::near().\n\n\nBoolean algebra and missing values\nCombine logical vectors using Boolean algebra. In R, & means and, | means or, ! means not, and xor() is exclusive‑or. The short‑circuiting operators && and || return a single TRUE/FALSE and should not be used inside functions like filter().\nMissing values are contagious: any comparison involving NA yields NA. In Boolean operations, NA | TRUE evaluates to TRUE but NA | FALSE remains NA. Use is.na() to test for missing values:\n\nflights |&gt; \n  summarise(\n    n_missing_dep = sum(is.na(dep_time)),\n    n_missing_arr = sum(is.na(arr_time))\n  )\n\n# A tibble: 1 × 2\n  n_missing_dep n_missing_arr\n          &lt;int&gt;         &lt;int&gt;\n1          8255          8713\n\n\nWhen combining conditions, remember the order of operations. To filter flights departing in November or December, write month == 11 | month == 12 or use %in%; writing month == 11 | 12 mistakenly recycles the vector c(11, 12).\n\n\nSummarising logical vectors\nLogical summaries collapse a logical vector to a single value. any(x) returns TRUE if any element of x is TRUE, while all(x) returns TRUE only if every element is TRUE. Both functions accept na.rm = TRUE to ignore missing values. For example, to check if all flights on a given day departed within an hour or if any flights arrived more than five hours late:\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarise(\n    all_dep_within_hour = all(dep_delay &lt;= 60, na.rm = TRUE),\n    any_long_arr_delay  = any(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# A tibble: 365 × 5\n    year month   day all_dep_within_hour any_long_arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;               &lt;lgl&gt;             \n 1  2013     1     1 FALSE               TRUE              \n 2  2013     1     2 FALSE               TRUE              \n 3  2013     1     3 FALSE               FALSE             \n 4  2013     1     4 FALSE               FALSE             \n 5  2013     1     5 FALSE               TRUE              \n 6  2013     1     6 FALSE               FALSE             \n 7  2013     1     7 FALSE               TRUE              \n 8  2013     1     8 FALSE               FALSE             \n 9  2013     1     9 FALSE               TRUE              \n10  2013     1    10 FALSE               TRUE              \n# ℹ 355 more rows\n\n\nSince logical vectors coerce to numeric (TRUE = 1, FALSE = 0), sum() counts the number of TRUE values and mean() computes their proportion. For instance, the proportion of flights departing within an hour and the number with very long arrival delays can be calculated by:\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarise(\n    prop_on_time_dep    = mean(dep_delay &lt;= 60, na.rm = TRUE),\n    count_long_arr_delay = sum(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# A tibble: 365 × 5\n    year month   day prop_on_time_dep count_long_arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;            &lt;dbl&gt;                &lt;int&gt;\n 1  2013     1     1            0.939                    3\n 2  2013     1     2            0.914                    3\n 3  2013     1     3            0.941                    0\n 4  2013     1     4            0.953                    0\n 5  2013     1     5            0.964                    1\n 6  2013     1     6            0.959                    0\n 7  2013     1     7            0.956                    1\n 8  2013     1     8            0.975                    0\n 9  2013     1     9            0.986                    1\n10  2013     1    10            0.977                    2\n# ℹ 355 more rows\n\n\nLogical vectors also enable inline subsetting. Rather than filtering the entire data frame, you can subset a single vector with a logical condition (e.g., arr_delay[arr_delay &gt; 0]) to compute summaries only on values meeting a criterion.\n\n\nNumeric vectors: making numbers and parsing\nNumeric vectors may be integers or doubles. When numbers are stored as text (e.g., \"$1,234\" or \"59%\"), use readr::parse_double() to convert simple numeric strings and readr::parse_number() to strip extraneous characters like currency symbols or percent signs.\n\n\nVectorized arithmetic and recycling\nR performs arithmetic element‑wise and recycles the shorter vector to match the length of the longer one. Recycling single numbers (e.g., x / 5) is convenient, but recycling longer vectors can produce warnings or silent errors. Avoid using == with vectors of unequal length; instead use %in% when matching multiple values.\nElement‑wise minima and maxima are computed with pmin() and pmax(). Modular arithmetic operators %/% and %% perform integer division and find remainders. For example, unpacking a four‑digit departure time into hours and minutes:\n\nflights |&gt;\n  mutate(\n    sched_hour   = sched_dep_time %/% 100,\n    sched_minute = sched_dep_time %% 100\n  ) |&gt;\n  select(sched_dep_time, sched_hour, sched_minute) |&gt;\n  head()\n\n# A tibble: 6 × 3\n  sched_dep_time sched_hour sched_minute\n           &lt;int&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1            515          5           15\n2            529          5           29\n3            540          5           40\n4            545          5           45\n5            600          6            0\n6            558          5           58\n\n\n\n\nNumeric transformations\nTo handle wide ranges of values, apply log transformations. log2() and log10() are easier to interpret; for example, a difference of 1 on the log2 scale corresponds to doubling or halving the original value. Rounding functions include round() (which uses banker’s rounding), floor() and ceiling(). To round to arbitrary multiples, scale the vector, round, and then scale back. Use cut() to convert a continuous variable into categories by specifying break points and optional labels.\n\nx = c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 20), labels = c(\"small\", \"medium\", \"large\"))\n\n[1] small  small  small  medium large  large \nLevels: small medium large\n\n\n\n\nNumeric summaries\nSummarizing numeric vectors involves measures of center and spread. The mean is sensitive to extreme values, while the median is more robust. The median daily departure delay is always smaller than the mean because flights can be hours late but rarely leave hours early. Quantiles generalize the median; for example, the 95th percentile ignores the most extreme 5% of values. Measures of spread include the standard deviation and the interquartile range (IQR), the difference between the 75th and 25th percentiles.\n\nflights |&gt;\n  summarise(\n    mean_arr_delay    = mean(arr_delay, na.rm = TRUE),\n    median_arr_delay  = median(arr_delay, na.rm = TRUE),\n    q95_arr_delay     = quantile(arr_delay, 0.95, na.rm = TRUE),\n    sd_arr_delay      = sd(arr_delay, na.rm = TRUE),\n    iqr_arr_delay     = IQR(arr_delay, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 5\n  mean_arr_delay median_arr_delay q95_arr_delay sd_arr_delay iqr_arr_delay\n           &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1           6.90               -5            91         44.6            31\n\n\n\n\nKey take‑aways\n\nLogical vectors arise from comparisons and contain only TRUE, FALSE and NA. Combine conditions with Boolean operators and handle missing values carefully.\nSummarize logical vectors with any(), all(), sum() and mean() to answer questions like “Were all flights on time?” or “What fraction of flights left within an hour?”.\nBe mindful of type when working with numbers. Parse numeric strings properly and avoid unintended recycling in arithmetic and comparisons.\nUse numeric transformations—element‑wise minima/maxima, modular arithmetic, logs, rounding and binning—to prepare variables for analysis.\nChoose appropriate summaries: mean vs. median for center, quantiles for tails, and standard deviation or IQR for spread.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Session 8 – Variable types I: logical & numeric vectors</span>"
    ]
  },
  {
    "objectID": "09.html",
    "href": "09.html",
    "title": "9  Session 9 – Variable types II: strings & regular expressions",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Session 9 – Variable types II: strings & regular expressions</span>"
    ]
  },
  {
    "objectID": "09.html#objectives",
    "href": "09.html#objectives",
    "title": "9  Session 9 – Variable types II: strings & regular expressions",
    "section": "",
    "text": "Create and manipulate strings. Recall that strings are sequences of characters defined by quotes. In R you can use single ' or double \" quotes to create strings. The R4DS text recommends using double quotes by default and switching to single quotes only when the string itself contains quotes. You’ll learn how to escape special characters like backslashes and newlines, how to measure string length with str_length(), and how to extract or replace substrings with str_sub().\nCombine and format strings. Concatenate strings using str_c() (stringr’s equivalent to paste0()), and build templated strings with str_glue(). Understand how these functions handle missing values and learn to collapse vectors of strings with str_flatten().\nUnderstand regular expressions. A regular expression (regex) is a concise language for describing patterns within strings. You’ll learn the difference between literal characters and metacharacters, how quantifiers like ?, * and + control repetition, and how to use character classes ([...]), alternation (|) and anchors (^, $).\nMatch, extract and replace patterns. Use str_detect() to test whether strings match a regex, str_count() to count the number of matches, str_extract() (and str_extract_all()) to pull out matching substrings, str_replace()/str_replace_all() to substitute patterns, and str_split() to separate strings at delimiters. Pair these functions with dplyr verbs to filter, mutate or summarize character variables.\nTidy multiple variables encoded in one string. Recognise when a single string stores several pieces of information and use stringr plus tidyr functions such as str_split() with unnest_longer() or separate() to unpack them. This sets the stage for the next session on factors.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Session 9 – Variable types II: strings & regular expressions</span>"
    ]
  },
  {
    "objectID": "09.html#notes",
    "href": "09.html#notes",
    "title": "9  Session 9 – Variable types II: strings & regular expressions",
    "section": "Notes",
    "text": "Notes\n\nCreating strings: quotes, escapes & length\nStrings can be created with single or double quotes. Double quotes are preferred by convention—use single quotes only when the string itself contains double quotes to avoid escaping. Special characters (backslash, newline, tab) require escaping with \\, \\n or \\t. For example:\n\nlibrary(tidyverse)\nlibrary(stringr)\n\n# A string containing both single and double quotes\nquote_example =  \"He said, 'R is great!'\"\nquote_example\n\n[1] \"He said, 'R is great!'\"\n\n# A string with a backslash and a newline\npath =  \"C:\\\\Users\\\\Data\\\\mydata\\n\"\npath\n\n[1] \"C:\\\\Users\\\\Data\\\\mydata\\n\"\n\n\nThe length of a string (number of characters) is computed with str_length(). Note that str_length() counts human‑visible characters, not bytes or graphemes—R treats each character as one unit regardless of encoding:\n\nstr_length(c(\"\", \"abc\", \"😊\"))\n\n[1] 0 3 1\n\n\nUse str_sub() to extract or replace substrings by position. Positive indices count from the start and negative indices count from the end. The function is vectorised, so you can operate on a vector of strings at once:\n\nfruit =  c(\"banana\", \"apple\", \"pear\")\nstr_sub(fruit, 1, 3)      # first three letters\n\n[1] \"ban\" \"app\" \"pea\"\n\nstr_sub(fruit, -3, -1)    # last three letters\n\n[1] \"ana\" \"ple\" \"ear\"\n\nstr_sub(fruit, 1, 1) =  str_to_upper(str_sub(fruit, 1, 1))  # capitalize first letter\nfruit\n\n[1] \"Banana\" \"Apple\"  \"Pear\"  \n\n\n\n\nCombining and formatting strings\nstr_c() concatenates multiple strings together and returns a character vector. It’s similar to paste0() but has a more consistent interface and works seamlessly with dplyr verbs. You can supply a sep argument to insert a separator and a collapse argument to collapse the result into a single string:\n\nspecies =  c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\nn =  c(3, 2, 1)\nstr_c(n, species, sep = \" \", collapse = \"; \")\n\n[1] \"3 Adelie; 2 Chinstrap; 1 Gentoo\"\n\n\nWhen concatenating across rows in a tibble, wrap str_c() inside mutate(). If any of the components are NA, the result will be NA. Use coalesce() to replace missing values with an empty string before concatenation:\n\nlibrary(dplyr)\ndf =  tibble(first = c(\"John\", NA, \"Jenny\"),\n             last  = c(\"Smith\", \"Nguyen\", NA))\ndf |&gt; mutate(full = str_c(coalesce(first, \"\"), coalesce(last, \"\"), sep = \" \"))\n\n# A tibble: 3 × 3\n  first last   full        \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;       \n1 John  Smith  \"John Smith\"\n2 &lt;NA&gt;  Nguyen \" Nguyen\"   \n3 Jenny &lt;NA&gt;   \"Jenny \"    \n\n\nstr_glue() from the glue package (loaded automatically with tidyverse) creates templated strings. Inside curly braces {}, you can insert arbitrary R expressions. Missing values are converted to the string “NA”:\n\nlibrary(glue)\ndf |&gt; mutate(message = str_glue(\"Hello {first} {last}!\"))\n\n# A tibble: 3 × 3\n  first last   message          \n  &lt;chr&gt; &lt;chr&gt;  &lt;glue&gt;           \n1 John  Smith  Hello John Smith!\n2 &lt;NA&gt;  Nguyen Hello NA Nguyen! \n3 Jenny &lt;NA&gt;   Hello Jenny NA!  \n\n\nIf you need to combine many strings into one, use str_flatten() rather than repeatedly adding separators. It collapses a character vector into a single string with a given delimiter:\n\nletters =  c(\"a\", \"b\", \"c\")\nstr_flatten(letters, collapse = \", \")\n\n[1] \"a, b, c\"\n\n\n\n\nRegular expressions: pattern basics\nA regular expression (regex) is a concise language for describing sets of strings. In regex, most letters and numbers match themselves (are literals), but certain characters have special meaning (metacharacters). Important metacharacters include:\n\n. matches any character except a newline.\nQuantifiers control repetition: ? matches zero or one occurrence; * matches zero or more; + matches one or more.\nCharacter classes like [aeiou] match any of the enclosed characters. A caret (^) at the start of a class negates it: [^0-9] matches any non‑digit.\nAlternation | matches one of several possibilities; for example, apple|pear matches either word.\nAnchors ^ and $ match the start and end of a string, respectively.\n\nUse regex() to build regexes with settings such as case‑insensitive matching (regex(pattern, ignore_case = TRUE)). The stringr package provides helper functions like str_view() and str_view_all() to visualize matches, but we’ll focus on functions that return useful vectors.\n\n\nDetecting, counting and extracting patterns\nstr_detect() tests whether each element of a character vector matches a regex and returns a logical vector. This pairs naturally with filter() to select rows matching a pattern. str_count() counts the number of times a pattern appears within each string. str_extract() returns the first match, and str_extract_all() returns all matches as a list. str_replace() and str_replace_all() replace the first or all matches with a new string. Finally, str_split() splits strings at matches of a regex and returns a list of pieces.\nLet’s illustrate with flight numbers from the nycflights13 dataset. Airlines in the United States identify a flight by a two‑letter carrier code followed by a flight number. We can build a flight ID string and then extract the numeric part:\n\nlibrary(nycflights13)\nflights_small =  flights |&gt; select(carrier, flight) |&gt; sample_n(5)\n\n# Combine carrier and flight into a single string\nflights_small =  flights_small |&gt; mutate(flight_id = str_c(carrier, flight, sep = \"-\"))\n\n# Detect whether the flight number has exactly 3 digits\nflights_small |&gt; mutate(is_three_digit = str_detect(flight_id, \"-\\\\d{3}$\"))\n\n# A tibble: 5 × 4\n  carrier flight flight_id is_three_digit\n  &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;     &lt;lgl&gt;         \n1 UA         544 UA-544    TRUE          \n2 EV        4672 EV-4672   FALSE         \n3 EV        4380 EV-4380   FALSE         \n4 UA         695 UA-695    TRUE          \n5 MQ        3737 MQ-3737   FALSE         \n\n# Extract the numeric part of the flight ID\nflights_small |&gt; mutate(number_only = str_extract(flight_id, \"\\\\d+\"))\n\n# A tibble: 5 × 4\n  carrier flight flight_id number_only\n  &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;      \n1 UA         544 UA-544    544        \n2 EV        4672 EV-4672   4672       \n3 EV        4380 EV-4380   4380       \n4 UA         695 UA-695    695        \n5 MQ        3737 MQ-3737   3737       \n\n\nNotice that \\d in a regex matches any digit (short for [0-9]), so \\d+ extracts one or more consecutive digits. We had to escape the backslash in the string to make sure it reached the regular‑expression engine.\nstr_replace_all() lets you perform substitutions. For example, you can strip all non‑digit characters from a string using the negated class [^0-9]:\n\nmessy =  c(\"(202) 555-0198\", \"+1-303-555-1212\")\nstr_replace_all(messy, \"[^0-9]\", \"\")\n\n[1] \"2025550198\"  \"13035551212\"\n\n\nFinally, str_split() (or str_split_fixed()) breaks a string into pieces at matches of a pattern. If you know your delimiter, you can also use tidyr’s separate() or separate_wider_delim() to split a column into multiple variables. For example, suppose we have a vector of names in “LAST, First Middle” format:\n\nnames =  c(\"SMITH, John A.\", \"O'NEILL, Anne\", \"Lee, Chen\")\n# Split at the comma and whitespace\ndf_names =  tibble(full = names) |&gt; separate(full, into = c(\"last\", \"rest\"), sep = \",\\\\s*\")\ndf_names\n\n# A tibble: 3 × 2\n  last    rest   \n  &lt;chr&gt;   &lt;chr&gt;  \n1 SMITH   John A.\n2 O'NEILL Anne   \n3 Lee     Chen   \n\n\n\n\nWorking with messy strings in tibbles\nCharacter columns often encode multiple variables in one field. To tidy them, combine stringr and tidyr. As an example, consider the built‑in who2 dataset where column names like sp_m_014 describe the diagnosis, gender and age group. We can pivot the data longer and then separate the compound names into distinct variables:\n\nlibrary(tidyr)\nwho2_long =  who2 |&gt; pivot_longer(\n  cols = !(country:year),\n  names_to = c(\"diagnosis\", \"gender\", \"age\"),\n  names_sep = \"_\",\n  values_to = \"count\"\n)\nwho2_long |&gt; head()\n\n# A tibble: 6 × 6\n  country      year diagnosis gender age   count\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1 Afghanistan  1980 sp        m      014      NA\n2 Afghanistan  1980 sp        m      1524     NA\n3 Afghanistan  1980 sp        m      2534     NA\n4 Afghanistan  1980 sp        m      3544     NA\n5 Afghanistan  1980 sp        m      4554     NA\n6 Afghanistan  1980 sp        m      5564     NA\n\n\n\n\nKey take‑aways\n\nStrings are enclosed in quotes; use double quotes by default and escape special characters like backslash (\\\\), newline (\\n) or tab (\\t). str_length() and str_sub() let you measure and manipulate substrings.\nConcatenate strings with str_c() and build templated strings with str_glue(). Use coalesce() to handle missing values and str_flatten() to collapse many strings into one.\nRegular expressions describe patterns. Learn the roles of metacharacters (., ?, *, +), character classes ([...]) and alternation (|), and how to anchor patterns at the start (^) or end ($) of a string.\nUse str_detect() to filter strings, str_count() to count occurrences, str_extract() to pull out matches, and str_replace()/str_replace_all() to perform substitutions. These functions are vectorised and integrate well with dplyr.\nTidy multiple variables encoded in one string by combining stringr with tidyr’s separate() and pivot_longer(). This prepares your data for converting character vectors to factors in the next session.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Session 9 – Variable types II: strings & regular expressions</span>"
    ]
  },
  {
    "objectID": "10.html",
    "href": "10.html",
    "title": "10  Session 10 – Variable types III: factors",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Session 10 – Variable types III: factors</span>"
    ]
  },
  {
    "objectID": "10.html#objectives",
    "href": "10.html#objectives",
    "title": "10  Session 10 – Variable types III: factors",
    "section": "",
    "text": "Understand why factors exist. Factors represent categorical variables with a fixed and known set of possible values. They prevent accidental typos and give you control over the order in which categories appear in summaries and plots. Learn why treating categories as strings can lead to problems and how factors solve those problems.\nCreate and inspect factors. Use factor() or forcats::fct() to convert character vectors to factors, specify levels and handle invalid values. Learn to inspect and summarize factor levels with levels() and count().\nReorder factor levels for better visualization. Use fct_reorder() to order levels by the values of another variable, fct_relevel() to manually move levels to the front and fct_reorder2() when ordering line‑plot legends. Explore fct_infreq() and fct_rev() to arrange levels by frequency.\nModify and collapse levels. Relabel categories with fct_recode(), combine multiple levels with fct_collapse() and lump rare categories into “other” with the fct_lump_*() family.\nWork with ordered factors. Create ordered factors for ordinal data (e.g., satisfaction ratings) and appreciate when an intrinsic order exists.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Session 10 – Variable types III: factors</span>"
    ]
  },
  {
    "objectID": "10.html#notes",
    "href": "10.html#notes",
    "title": "10  Session 10 – Variable types III: factors",
    "section": "Notes",
    "text": "Notes\n\nWhy factors?\nIn data analysis, categorical variables often have a limited set of allowed values (e.g., months, continents, income bands). Storing them as plain strings introduces two common issues: you can type invalid values and the default alphabetical sorting is rarely meaningful. A factor solves these problems by enforcing a list of valid levels and providing explicit control over their order. For example, the months “Jan”, “Feb”, … “Dec” should appear in calendar order, not alphabetical. Converting a character vector of month names to a factor with those 12 levels ensures that invalid spellings become missing values (or an error if you use forcats::fct()), and sorting follows the chosen level order.\nFactors are also necessary for plotting. When you map a factor to the y‑axis of a bar chart or to color/shape, ggplot2 displays the categories in the order given by the factor. If you leave your categorical variable as a character, ggplot2 silently converts it to a factor using the alphabetical order.\n\n\nCreating factors\nBase R provides a factor() function. You pass a character vector and optionally a vector of levels:\n\nlibrary(tidyverse)\n\nmonths_raw  = c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\nmonth_levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n                 \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\n# Create a factor with explicit levels\nmonths_factor = factor(months_raw, levels = month_levels)\nmonths_factor\n\n[1] Dec Apr Jan Mar\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nIf a value does not appear in levels, factor() converts it to NA. The forcats package (loaded with the tidyverse) provides fct() which raises an error if you try to create a factor from values not present in levels, helping you catch typos earlier.\nYou can check the current levels with levels(months_factor) and count the number of observations in each category using count():\n\nlibrary(forcats)\n\nlevels(months_factor)  # returns the vector of valid levels\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\n# Example using the gss_cat dataset from forcats\ngss_cat |&gt; count(race)\n\n# A tibble: 3 × 2\n  race      n\n  &lt;fct&gt; &lt;int&gt;\n1 Other  1959\n2 Black  3129\n3 White 16395\n\n\nThe gss_cat dataset (part of forcats) contains multiple factor variables such as race, marital, rincome and partyid. Use it to practice summarizing and visualizing categorical data.\n\n\nReordering levels\nSometimes the alphabetical or default order of factor levels is arbitrary. Reordering levels improves the interpretability of plots. The fct_reorder() function takes three arguments: the factor to reorder, a numeric vector whose values determine the order, and optionally a function to combine multiple values.\n\n# Average TV hours by religion\nrelig_summary = gss_cat |&gt;\n  group_by(relig) |&gt;\n  summarise(tvhours = mean(tvhours, na.rm = TRUE), .groups = \"drop\")\n\n# Plot without reordering\nggplot(relig_summary, aes(x = tvhours, y = relig)) +\n  geom_point()\n\n\n\n\n\n\n\n# Plot with levels reordered by tvhours\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n  geom_point()\n\n\n\n\n\n\n\n\nHere, reordering the relig factor makes it clear that people in the “Don’t know” category watch more TV than those in “Other Eastern” religions. Use fct_relevel() when you need to manually move one or more levels to the front—for example, to emphasize a special category:\n\n# Move \"Not applicable\" to the front in rincome\nrincome_summary = gss_cat |&gt;\n  group_by(rincome) |&gt;\n  summarise(age = mean(age, na.rm = TRUE), .groups = \"drop\")\n\nggplot(rincome_summary, aes(x = age, y = fct_relevel(rincome, \"Not applicable\"))) +\n  geom_point()\n\n\n\n\n\n\n\n\nFor line plots with many categories, fct_reorder2() orders the legend by the y‑value at the largest x‑value, making it easier to match the lines to the legend.\nFinally, fct_infreq() orders levels by their frequency, and fct_rev() reverses that order. This combination is useful for bar charts where you want categories sorted from least to most common.\n\n\nModifying levels\nReordering controls the order of the levels, but sometimes you want to change the labels or combine categories. The fct_recode() function renames levels by providing the new name on the left and the old name on the right:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\"\n    )\n  ) |&gt;\n  count(partyid)\n\n# A tibble: 10 × 2\n   partyid                   n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 No answer               154\n 2 Don't know                1\n 3 Other party             393\n 4 Republican, strong     2314\n 5 Republican, weak       3032\n 6 Independent, near rep  1791\n 7 Independent            4119\n 8 Independent, near dem  2499\n 9 Democrat, weak         3690\n10 Democrat, strong       3490\n\n\nTo collapse multiple categories into a smaller set, use fct_collapse(). Supply the new category names and a vector of existing levels to combine:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_collapse(partyid,\n      other = c(\"No answer\", \"Don't know\", \"Other party\"),\n      rep   = c(\"Strong republican\", \"Not str republican\"),\n      ind   = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n      dem   = c(\"Not str democrat\", \"Strong democrat\")\n    )\n  ) |&gt;\n  count(partyid)\n\n# A tibble: 4 × 2\n  partyid     n\n  &lt;fct&gt;   &lt;int&gt;\n1 other     548\n2 rep      5346\n3 ind      8409\n4 dem      7180\n\n\nWhen you need to simplify a factor with many rare categories, the fct_lump_*() family automatically groups the smallest categories into “Other”. For example, fct_lump_n(factor, n = 10) keeps the 10 most common categories and lumps the rest:\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_n(relig, n = 10)) |&gt;\n  count(relig, sort = TRUE)\n\n# A tibble: 10 × 2\n   relig                       n\n   &lt;fct&gt;                   &lt;int&gt;\n 1 Protestant              10846\n 2 Catholic                 5124\n 3 None                     3523\n 4 Christian                 689\n 5 Other                     458\n 6 Jewish                    388\n 7 Buddhism                  147\n 8 Inter-nondenominational   109\n 9 Moslem/islam              104\n10 Orthodox-christian         95\n\n\n\n\nOrdered factors\nSome categories have an intrinsic order (e.g., “low”, “medium”, “high” or rating scales from 1 to 5). You can create an ordered factor by setting ordered = TRUE in factor() or using forcats::fct() with the ordered argument. Ordered factors behave like numeric variables for certain operations (e.g., min() and max() work) but remain categorical. Always think carefully about whether your categories truly have a natural order before imposing one.\n\n\nKey take‑aways\n\nFactors represent categorical variables with a fixed set of levels and control the order of categories.\nCreating a factor from a string requires specifying the valid levels; values not in the list become NA or throw an error.\nInspect factor levels with levels() and summarise them with count().\nUse the forcats functions fct_reorder(), fct_relevel() and fct_reorder2() to rearrange levels for clearer plots.\nModify factor labels with fct_recode(), collapse levels with fct_collapse() and lump rare categories with fct_lump_n().\nOrdered factors capture ordinal scales—set ordered = TRUE when the categories have a meaningful ranking.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Session 10 – Variable types III: factors</span>"
    ]
  }
]